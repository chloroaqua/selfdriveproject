\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{udacity}
\citation{pomerleau1989alvinn}
\citation{bojarski2016end}
\citation{bojarski2016end}
\citation{bojarski2016end}
\citation{karpathy2014large}
\citation{farabet2013learning}
\citation{szegedy2013deep}
\citation{Tran_2015_ICCV}
\citation{yue2015beyond}
\citation{he2016deep}
\citation{huang2016densely}
\@writefile{toc}{\contentsline {section}{\numberline {1}\hskip -1em.\nobreakspace  {}Introduction}{1}{section.1}}
\@writefile{toc}{\contentsline {section}{\numberline {2}\hskip -1em.\nobreakspace  {}Related Work}{1}{section.2}}
\citation{santana2016learning}
\citation{kingma2013auto}
\citation{goodfellow2014generative}
\citation{el2017deep}
\citation{shalev2016safe}
\citation{mnih2013playing}
\citation{silver2016mastering}
\citation{el2017deep}
\citation{ioffe2015batch}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces CNN architecture used in \cite  {bojarski2016end}. The network contains approximately 27 million connections and 250 thousand parameters.}}{2}{figure.1}}
\newlabel{nvidiaimage}{{1}{2}{CNN architecture used in \cite {bojarski2016end}. The network contains approximately 27 million connections and 250 thousand parameters}{figure.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}\hskip -1em.\nobreakspace  {}Methods}{2}{section.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}\hskip -1em.\nobreakspace  {}3D Convolutional Model with Residual Connections and Recurrent LSTM Layers}{2}{subsection.3.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.1}3D Convolutional Layer}{2}{subsubsection.3.1.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.2}Residual Connection}{2}{subsubsection.3.1.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.3}Spatial Batch Normalization}{2}{subsubsection.3.1.3}}
\citation{he2016deep}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.4}Recurrent Neural Networks and Long Short Term Memory}{3}{subsubsection.3.1.4}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.5}New Architecture}{3}{subsubsection.3.1.5}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces 3D convolutional model with residual connections and recurrent LSTM layers}}{3}{figure.2}}
\newlabel{3dconvlstm_graph}{{2}{3}{3D convolutional model with residual connections and recurrent LSTM layers}{figure.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}\hskip -1em.\nobreakspace  {}Transfer Learning}{3}{subsection.3.2}}
\citation{bojarski2016end}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Architecture used for transfer learning model.}}{4}{figure.3}}
\newlabel{resnet50}{{3}{4}{Architecture used for transfer learning model}{figure.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}\hskip -1em.\nobreakspace  {}Dataset and Features}{4}{section.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Example images from the dataset. From left to right, bight sun, shadows, sharp left turn, up hill, straight, and heavy traffic conditions.}}{4}{figure.4}}
\newlabel{example_images}{{4}{4}{Example images from the dataset. From left to right, bight sun, shadows, sharp left turn, up hill, straight, and heavy traffic conditions}{figure.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}\hskip -1em.\nobreakspace  {}Data Augmentation Methods}{4}{subsection.4.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.1}Brightness Augmentation}{4}{subsubsection.4.1.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.2}Shadow Augmentation}{4}{subsubsection.4.1.2}}
\citation{bojarski2016end}
\citation{bojarski2016end}
\citation{kingma2014adam}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Brightness augmentation examples}}{5}{figure.5}}
\newlabel{bright_aug}{{5}{5}{Brightness augmentation examples}{figure.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Shadow augmentation examples}}{5}{figure.6}}
\newlabel{shadow_aug}{{6}{5}{Shadow augmentation examples}{figure.6}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.3}Horizontal and Vertical Shifts}{5}{subsubsection.4.1.3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.4}Rotation Augmentation}{5}{subsubsection.4.1.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}\hskip -1em.\nobreakspace  {}Preprocessing}{5}{subsection.4.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Shift augmentation examples}}{5}{figure.7}}
\newlabel{shift_aug}{{7}{5}{Shift augmentation examples}{figure.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Rotation augmentation example}}{5}{figure.8}}
\newlabel{rotaion_aug}{{8}{5}{Rotation augmentation example}{figure.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}\hskip -1em.\nobreakspace  {}Experiments, Results, and Discussion}{5}{section.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}\hskip -1em.\nobreakspace  {}Data Augmentation}{5}{subsection.5.1}}
\citation{kingma2014adam}
\citation{bojarski2017explaining}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces RMSE on the validation set using the NVIDIA architecture for different levels of data augmentation with 32 epochs.}}{6}{table.1}}
\newlabel{data_aug_table}{{1}{6}{RMSE on the validation set using the NVIDIA architecture for different levels of data augmentation with 32 epochs}{table.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}\hskip -1em.\nobreakspace  {}Training Process}{6}{subsection.5.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.1}Loss Function and Optimization}{6}{subsubsection.5.2.1}}
\newlabel{mse}{{1}{6}{Loss Function and Optimization}{equation.5.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}\hskip -1em.\nobreakspace  {}Feature Visualization}{6}{subsection.5.3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.1}Data Augmentation Experiment}{6}{subsubsection.5.3.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces NVIDIA model saliency maps for different levels of augmentation.}}{6}{figure.9}}
\newlabel{nvidia_aug}{{9}{6}{NVIDIA model saliency maps for different levels of augmentation}{figure.9}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.2}3D Convolutional LSTM Model}{6}{subsubsection.5.3.2}}
\citation{udacity}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Saliency map for a sequence in the 3D convolutional LSTM model for an example image.}}{7}{figure.10}}
\newlabel{3d_full}{{10}{7}{Saliency map for a sequence in the 3D convolutional LSTM model for an example image}{figure.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Saliency map for the 3D convolutional LSTM model for an example image.}}{7}{figure.11}}
\newlabel{3d_collapse}{{11}{7}{Saliency map for the 3D convolutional LSTM model for an example image}{figure.11}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.3}Transfer Learning Model}{7}{subsubsection.5.3.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4}\hskip -1em.\nobreakspace  {}Results}{7}{subsection.5.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Transfer learning model (ResNet50) saliency map for an example image.}}{7}{figure.12}}
\newlabel{resnet50_saliency}{{12}{7}{Transfer learning model (ResNet50) saliency map for an example image}{figure.12}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces RMSE for the models on the Udacity dataset.}}{7}{table.2}}
\newlabel{model_results}{{2}{7}{RMSE for the models on the Udacity dataset}{table.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5}\hskip -1em.\nobreakspace  {}Discussion}{7}{subsection.5.5}}
\bibstyle{ieee}
\bibdata{egbib}
\bibcite{bojarski2016end}{1}
\bibcite{bojarski2017explaining}{2}
\bibcite{el2017deep}{3}
\bibcite{farabet2013learning}{4}
\bibcite{goodfellow2014generative}{5}
\bibcite{he2016deep}{6}
\bibcite{huang2016densely}{7}
\bibcite{ioffe2015batch}{8}
\bibcite{karpathy2014large}{9}
\bibcite{kingma2014adam}{10}
\bibcite{kingma2013auto}{11}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Example actual vs. predicted angle on unprocessed images (transfer model).}}{8}{figure.13}}
\newlabel{angle_overlay}{{13}{8}{Example actual vs. predicted angle on unprocessed images (transfer model)}{figure.13}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}\hskip -1em.\nobreakspace  {}Conclusion and Future Work}{8}{section.6}}
\bibcite{mnih2013playing}{12}
\bibcite{pomerleau1989alvinn}{13}
\bibcite{santana2016learning}{14}
\bibcite{shalev2016safe}{15}
\bibcite{silver2016mastering}{16}
\bibcite{szegedy2013deep}{17}
\bibcite{Tran_2015_ICCV}{18}
\bibcite{udacity}{19}
\bibcite{yue2015beyond}{20}
